{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import cvxpy as cp\n",
    "import collections\n",
    "import random\n",
    "%matplotlib notebook \n",
    "%matplotlib inline   \n",
    "\n",
    "from systems_and_functions.control_affine_system import ControlAffineSystem\n",
    "from systems_and_functions.cart_pole_system import CartPole\n",
    "from systems_and_functions.inverted_pendulum_system import InvertedPendulum\n",
    "from systems_and_functions.networks import PolicyNet, QValueNet\n",
    "from systems_and_functions.ddpg_process import DDPGProcess\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "np.random.seed(13)\n",
    "\n",
    "torch.manual_seed(30)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(30)\n",
    "    torch.cuda.manual_seed_all(30)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Controller is involved.\n",
      "tensor([0., 0.], device='cuda:0')\n",
      "linearized_ct_system:\n",
      " A[[ 0.   1. ]\n",
      " [ 9.8 -0.5]],\n",
      " B[[0.]\n",
      " [1.]]\n",
      "computed LQR controller is [[19.65088867  5.86802774]]\n",
      "-------------------------------Main Iteration------------------------------\n",
      "---------------------Initializing Policy------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ICRA\\DOPT-main\\systems_and_functions\\ddpg_process.py:123: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  K = torch.tensor(-self.system.K)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Convergence Speed and Judgment-----------------\n",
      "--------------It takes 90 steps to norm 2 ball;--------------\n",
      "---------------It takes 114 steps to unit ball;---------------\n",
      "----------------It takes 175 steps to converge.--------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ICRA\\DOPT-main\\systems_and_functions\\inverted_pendulum_system.py:227: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------Iteration 1-------------------------------\n",
      "---------------------Sampling Training Data---------------------\n",
      "---------------------Updating Actor & Critic--------------------\n",
      "-----------------------Updating Critic----------------------\n",
      "------------------------Updating Actor----------------------\n",
      "-----------------Convergence Speed and Judgment-----------------\n",
      "--------------It takes 90 steps to norm 2 ball;--------------\n",
      "---------------It takes 113 steps to unit ball;---------------\n",
      "----------------It takes 176 steps to converge.--------------\n",
      "----------------------------------Save Data--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ICRA\\DOPT-main\\systems_and_functions\\ddpg_process.py:95: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------Iteration 2-------------------------------\n",
      "---------------------Sampling Training Data---------------------\n",
      "---------------------Updating Actor & Critic--------------------\n",
      "-----------------------Updating Critic----------------------\n",
      "------------------------Updating Actor----------------------\n",
      "-----------------Convergence Speed and Judgment-----------------\n",
      "--------------It takes 90 steps to norm 2 ball;--------------\n",
      "---------------It takes 113 steps to unit ball;---------------\n",
      "----------------It takes 173 steps to converge.--------------\n",
      "----------------------------------Save Data--------------------------------\n",
      "---------------------------------Iteration 3-------------------------------\n",
      "---------------------Sampling Training Data---------------------\n",
      "---------------------Updating Actor & Critic--------------------\n",
      "-----------------------Updating Critic----------------------\n",
      "------------------------Updating Actor----------------------\n",
      "-----------------Convergence Speed and Judgment-----------------\n",
      "--------------It takes 90 steps to norm 2 ball;--------------\n",
      "---------------It takes 113 steps to unit ball;---------------\n",
      "----------------It takes 171 steps to converge.--------------\n",
      "----------------------------------Save Data--------------------------------\n",
      "---------------------------------Iteration 4-------------------------------\n",
      "---------------------Sampling Training Data---------------------\n",
      "---------------------Updating Actor & Critic--------------------\n",
      "-----------------------Updating Critic----------------------\n",
      "------------------------Updating Actor----------------------\n",
      "-----------------Convergence Speed and Judgment-----------------\n",
      "--------------It takes 90 steps to norm 2 ball;--------------\n",
      "---------------It takes 112 steps to unit ball;---------------\n",
      "----------------It takes 171 steps to converge.--------------\n",
      "----------------------------------Save Data--------------------------------\n",
      "---------------------------------Iteration 5-------------------------------\n",
      "---------------------Sampling Training Data---------------------\n",
      "---------------------Updating Actor & Critic--------------------\n",
      "-----------------------Updating Critic----------------------\n",
      "------------------------Updating Actor----------------------\n",
      "-----------------Convergence Speed and Judgment-----------------\n",
      "--------------It takes 89 steps to norm 2 ball;--------------\n",
      "---------------It takes 111 steps to unit ball;---------------\n",
      "----------------It takes 168 steps to converge.--------------\n",
      "----------------------------------Save Data--------------------------------\n",
      "---------------------------------Iteration 6-------------------------------\n",
      "---------------------Sampling Training Data---------------------\n",
      "---------------------Updating Actor & Critic--------------------\n",
      "-----------------------Updating Critic----------------------\n",
      "------------------------Updating Actor----------------------\n",
      "-----------------Convergence Speed and Judgment-----------------\n",
      "--------------It takes 89 steps to norm 2 ball;--------------\n",
      "---------------It takes 111 steps to unit ball;---------------\n",
      "----------------It takes 168 steps to converge.--------------\n",
      "----------------------------------Save Data--------------------------------\n",
      "---------------------------------Iteration 7-------------------------------\n",
      "---------------------Sampling Training Data---------------------\n",
      "---------------------Updating Actor & Critic--------------------\n",
      "-----------------------Updating Critic----------------------\n",
      "------------------------Updating Actor----------------------\n",
      "-----------------Convergence Speed and Judgment-----------------\n",
      "--------------It takes 88 steps to norm 2 ball;--------------\n",
      "---------------It takes 110 steps to unit ball;---------------\n",
      "----------------It takes 170 steps to converge.--------------\n",
      "----------------------------------Save Data--------------------------------\n",
      "---------------------------------Iteration 8-------------------------------\n",
      "---------------------Sampling Training Data---------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 23\u001b[0m\n\u001b[0;32m      9\u001b[0m p1\u001b[38;5;241m.\u001b[39mlinearize_and_compute_LQR()\n\u001b[0;32m     11\u001b[0m ddpg1 \u001b[38;5;241m=\u001b[39m DDPGProcess(system \u001b[38;5;241m=\u001b[39m p1,\n\u001b[0;32m     12\u001b[0m                     n_hiddens_policy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m     13\u001b[0m                     n_hiddens_critic \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m                     device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     20\u001b[0m                     save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexperiment_results/DDPG/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m ddpg1\u001b[38;5;241m.\u001b[39mDDPG_main_iteration(iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m40\u001b[39m,\n\u001b[0;32m     24\u001b[0m                           plot_x_initial \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m2\u001b[39m],[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]]),\n\u001b[0;32m     25\u001b[0m                           plot_step_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m)\n",
      "File \u001b[1;32md:\\ICRA\\DOPT-main\\systems_and_functions\\ddpg_process.py:378\u001b[0m, in \u001b[0;36mDDPGProcess.DDPG_main_iteration\u001b[1;34m(self, iteration, plot_x_initial, plot_step_num)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, iteration\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m---------------------------------Iteration \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i))\n\u001b[1;32m--> 378\u001b[0m     sim_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_training_data(sample_radius_trajectory \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m    379\u001b[0m                                         sample_trajectory_number \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    380\u001b[0m                                         sample_number_per_trajectory \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    381\u001b[0m                                         sample_radius_random \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m,\n\u001b[0;32m    382\u001b[0m                                         sample_number_in_radius \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m,\n\u001b[0;32m    383\u001b[0m                                         \u001b[38;5;66;03m# sample_number_in_radius = 0,\u001b[39;00m\n\u001b[0;32m    384\u001b[0m                                         invariant_sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    385\u001b[0m                                         sample_plot \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    386\u001b[0m                                         the_controller \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor\u001b[38;5;241m.\u001b[39mController,\n\u001b[0;32m    387\u001b[0m                                         title \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample training data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer_add_sampledata(sim_data)\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer_size() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_training_batch:\n\u001b[0;32m    391\u001b[0m         \u001b[38;5;66;03m# sim_data = self.sample_training_data(sample_radius_trajectory = 0,\u001b[39;00m\n\u001b[0;32m    392\u001b[0m         \u001b[38;5;66;03m#                                 sample_trajectory_number = 0,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[38;5;66;03m#                                 the_controller = self.actor.Controller,\u001b[39;00m\n\u001b[0;32m    399\u001b[0m         \u001b[38;5;66;03m#                                 title = 'sample training data')\u001b[39;00m\n",
      "File \u001b[1;32md:\\ICRA\\DOPT-main\\systems_and_functions\\ddpg_process.py:195\u001b[0m, in \u001b[0;36mDDPGProcess.sample_training_data\u001b[1;34m(self, sample_radius_trajectory, sample_trajectory_number, sample_number_per_trajectory, sample_radius_random, sample_number_in_radius, invariant_sample, sample_plot, the_controller, title)\u001b[0m\n\u001b[0;32m    193\u001b[0m theta__, r__ \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m    194\u001b[0m x_0_radius \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[r__ \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mcos(theta__)],[r__ \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msin(theta__)]])\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m--> 195\u001b[0m one_step_euler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msystem\u001b[38;5;241m.\u001b[39mone_step_euler(x_0_radius,\u001b[38;5;241m1\u001b[39m,the_controller)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    196\u001b[0m x \u001b[38;5;241m=\u001b[39m one_step_euler[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    197\u001b[0m x_dot \u001b[38;5;241m=\u001b[39m one_step_euler[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32md:\\ICRA\\DOPT-main\\systems_and_functions\\control_affine_system.py:143\u001b[0m, in \u001b[0;36mControlAffineSystem.one_step_euler\u001b[1;34m(self, x_0, use_controller, the_controller)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m i \u001b[38;5;241m%\u001b[39m controller_update_freq \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    141\u001b[0m     u \u001b[38;5;241m=\u001b[39m the_controller(x_current\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice))\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m--> 143\u001b[0m x_dot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_dot(x_current, u)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    144\u001b[0m data_sim[i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, :, :] \u001b[38;5;241m=\u001b[39m x_dot\n\u001b[0;32m    145\u001b[0m data_sim[i, \u001b[38;5;241m0\u001b[39m, :, :] \u001b[38;5;241m=\u001b[39m x_current \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdt \u001b[38;5;241m*\u001b[39m x_dot\n",
      "File \u001b[1;32md:\\ICRA\\DOPT-main\\systems_and_functions\\inverted_pendulum_system.py:68\u001b[0m, in \u001b[0;36mInvertedPendulum.x_dot\u001b[1;34m(self, x, u)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mx_dot\u001b[39m(\n\u001b[0;32m     63\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     64\u001b[0m         x: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m     65\u001b[0m         u: torch\u001b[38;5;241m.\u001b[39mTensor\n\u001b[0;32m     66\u001b[0m ):\n\u001b[0;32m     67\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_f(x)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m---> 68\u001b[0m     g \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_g(x)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m     69\u001b[0m     x_dot \u001b[38;5;241m=\u001b[39m f \u001b[38;5;241m+\u001b[39m g \u001b[38;5;241m@\u001b[39m u\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x_dot\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params={'m': 1,'L': 1.0, 'b': 0.5}\n",
    "controller_params = {'K':np.array([[15,  4]])}\n",
    "# controller_params = {'K':np.array([[14,  3]])}\n",
    "p1 = InvertedPendulum(system_params = params,\n",
    "                      controller_params = controller_params,\n",
    "                      dt = 0.01, \n",
    "                      controller_period = 0.01)\n",
    "\n",
    "p1.linearize_and_compute_LQR()\n",
    "\n",
    "ddpg1 = DDPGProcess(system = p1,\n",
    "                    n_hiddens_policy = 32,\n",
    "                    n_hiddens_critic = 64,\n",
    "                    sigma = 0.5,\n",
    "                    tau = 0.3,\n",
    "                    gamma = 0.9,\n",
    "                    replay_buffer_capacity = 2000,\n",
    "                    min_training_batch = 1000,\n",
    "                    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'),\n",
    "                    save_path = 'experiment_results/DDPG/')\n",
    "\n",
    "\n",
    "ddpg1.DDPG_main_iteration(iteration = 40,\n",
    "                          plot_x_initial = torch.tensor([[2],[-2]]),\n",
    "                          plot_step_num = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg1.initialize_policy_net(x_train_lim = 10,\n",
    "                                    x_test_lim = 12,\n",
    "                                    sample_num = 2000,\n",
    "                                    iteration = 1*10**4,\n",
    "                                    lr = 1e-3)\n",
    "\n",
    "sim_data_ = ddpg1.system.simulate_rk4(x_initial = torch.tensor([[2],[-2]]), \n",
    "                                            step_number = 200,\n",
    "                                            use_controller = 1,\n",
    "                                            the_controller = ddpg1.actor.Controller)\n",
    "step2norm2ball,step2unitball,step2converge = ddpg1.system.convergence_judgment(sim_data_)\n",
    "\n",
    "ddpg1.system.plot_phase_portrait(data_sim = sim_data_,\n",
    "                        arrow_on = 0,\n",
    "                        title = 'after PI in iteration {}'.format(0),\n",
    "                        save_fig = 0,\n",
    "                        save_path =  ddpg1.save_path + 'figs/')\n",
    "\n",
    "print('reward: ',ddpg1.record_rollout_reward(sim_data_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
